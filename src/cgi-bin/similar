#!/usr/bin/env python 

# Import modules for CGI handling 
import cgi, cgitb 

# Create instance of FieldStorage 
form = cgi.FieldStorage() 

# Get data from fields
paper = form.getvalue('paper')
query = form.getvalue('query')
npapers = form.getvalue('limit')
if npapers is None:
    npapers = 5
npapers = int(npapers)

#!/usr/bin/env python

import sys,os,struct,json,requests
import numpy as np

print(sys.argv, file=sys.stderr)
apikey=os.environ.get('SPECTER_API_KEY')

def map_int64(fn):
    fn_len = os.path.getsize(fn)
    return np.memmap(fn, dtype=np.int64, shape=(int(fn_len/8)), mode='r')

bigrams_file = os.environ.get('JSALTdir') + '/semantic_scholar/embeddings/proposed/bigrams'
# bigrams_file = os.environ.get('JSALTdir') + '/semantic_scholar/embeddings/specter2/bigrams'
idx = map_int64(bigrams_file + '.idx')

def id_ify(s):
    if args.search or len(s) == 40 or args.API == 'author':
        return s
    for prefix in ['CorpusId:', 'PMID:', 'ACL:', 'arXiv:', 'DBLP:', 'MAG:', 'PMID:']:
        if s.startswith(prefix):
            return s
    if '/' in s: return s
    return 'CorpusId:' + s

def fetch_from_semantic_scholar(corpusId):
    try:
        my_api = 'https://api.semanticscholar.org/graph/v1/paper/CorpusId:'
        cmd = my_api + str(corpusId) + '/?fields=title,url'
        j = requests.get(cmd, headers={"x-api-key": apikey}).json()
        print(j, file=sys.stderr)
        return '<a href="%s">%s</a>' % (j['url'], j['title'])
    except:
        return str(corpusId)

def fetch_corpusId(id):
    try:
        cmd = 'https://api.semanticscholar.org/graph/v1/paper/' + str(id) + '/?fields=externalIds'
        j = requests.get(cmd, headers={"x-api-key": apikey}).json()
        print(j, file=sys.stderr)
        return j['externalIds']['CorpusId']
    except:
        return None

def lookup_paper(paper):
    try:
        query = int(paper)
        start = idx[query]
        end = idx[query+1]
        nbytes = 12*(end - start)
        with open(bigrams_file, 'rb') as fd:
            fd.seek(start * 12)
            bytes = fd.read(nbytes)
            res = sorted([record for record in struct.iter_unpack('fii', bytes)], key=lambda rec: rec[0], reverse=True)
            if len(res) > npapers: res = res[0:npapers]
            return res
    except:
        return []

def do_paper(paper):
    print("<h2>Input paper: %s; query=%s</h2>" % (paper, query))
    print("<ol>")
    for score, id1, id2 in lookup_paper(paper):
        print("<li>%0.3f %s</li>" % (score, fetch_from_semantic_scholar(id2)))
    print("</ol>")

print("Content-type:text/html\r\n\r\n")
print("<html>")
print("<head>")
print("<title>Similar</title>")
print("</head>")
print("<body>")

if not query is None:
    j = requests.get('https://api.semanticscholar.org/graph/v1/paper/autocomplete?query=' + query, headers={"x-api-key": apikey}).json()
    for m in j['matches']:
        print('query: <a href="https://www.semanticscholar.org/paper/%s">%s</a>' % (m['id'], m['title']))
        do_paper(fetch_corpusId(m['id']))
else:
    do_paper(paper)
print("</ol>")
print("</body>")
print("</html>")


