{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from collections import defaultdict, namedtuple\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import jsonlines\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_paper_by_ids(paperIds):\n",
    "    r = requests.post(\n",
    "        'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "        params={'fields': 'citationCount,title,corpusId'},\n",
    "        json={\"ids\": paperIds}\n",
    "    )\n",
    "    return(r.json())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Helpers from https://github.com/kwchurch/JSALT_Better_Together/blob/main/src/create_rotation_matrix.py\n",
    "\n",
    "def record_size_from_dir(dir):\n",
    "    with open(dir + '/record_size', 'r') as fd:\n",
    "        return int(fd.read().split('\\t')[0])\n",
    "\n",
    "def map_from_dir(dir):\n",
    "    fn = dir + '/map.old_to_new.i'\n",
    "    fn_len = os.path.getsize(fn)\n",
    "    return np.memmap(fn, dtype=np.int32, shape=(int(fn_len/4)), mode='r')\n",
    "\n",
    "def embedding_from_dir(dir, K):\n",
    "    fn = dir + '/embedding.f'\n",
    "    fn_len = os.path.getsize(fn)\n",
    "    return np.memmap(fn, dtype=np.float32, shape=(int(fn_len/(4*K)), K), mode='r')\n",
    "\n",
    "def directory_to_config(dir):\n",
    "    K = record_size_from_dir(dir)\n",
    "    return { 'record_size' : K,\n",
    "             'dir' : dir,\n",
    "             'map' : map_from_dir(dir),\n",
    "             'embedding' : embedding_from_dir(dir, K)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "specter = '/Volumes/kwc_JSALT/JSALTdir/semantic_scholar/embeddings/specter'\n",
    "proposed = '/Volumes/kwc_JSALT/JSALTdir/semantic_scholar/embeddings/proposed'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "inputs = specter, proposed\n",
    "\n",
    "configs = [directory_to_config(d) for d in inputs]\n",
    "\n",
    "map0 = configs[0]['map']\n",
    "emb0 = configs[0]['embedding']\n",
    "\n",
    "map1 = configs[1]['map']\n",
    "emb1 = configs[1]['embedding']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(map1[8])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "768\n",
      "0.068  seconds wall time to fetch specter & proposed.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time() # measure wall time\n",
    "print(len(emb1[map1[278919]]))\n",
    "print(len(emb0[map0[278919]]))\n",
    "print(format(time.time() - t0, \".3f\"), \" seconds wall time to fetch specter & proposed.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "PATH = '/Users/shabnamtafreshi/Desktop/JSULT/paper_reviewer_matching/'\n",
    "softFile = 'test_soft_qrel'\n",
    "hardFile = 'test_hard_qrel'\n",
    "reviewer_metafile = 'reviewer_metadata'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def gen_corpusId_potential_reviewrs(softFile, hardFile):\n",
    "    t0 = time.time() # measure wall time\n",
    "    specter_dataset_local = {}\n",
    "    proposed_dataset_local = {}\n",
    "    corpusId_potential_reviewrs = {}\n",
    "    files = [softFile, hardFile]\n",
    "    for file in files:\n",
    "        with jsonlines.open(PATH + file + '.jsonl') as reader:\n",
    "            for obj in reader:\n",
    "                if 'icip' not in str(obj[\"query_id\"]) and int(obj[\"query_id\"]) not in specter_dataset_local.keys():\n",
    "                    specter_dataset_local[obj[\"query_id\"]] = emb0[map0[int(obj[\"query_id\"])].tolist()]\n",
    "                    proposed_dataset_local[obj[\"query_id\"]] = emb1[map1[int(obj[\"query_id\"])].tolist()]\n",
    "                if 'icip' not in str(obj[\"query_id\"]):\n",
    "                    if str(obj[\"query_id\"]) not in corpusId_potential_reviewrs.keys():\n",
    "                        corpusId_potential_reviewrs[obj[\"query_id\"]] = obj['cand_id']\n",
    "                    else:\n",
    "                        corpusId_potential_reviewrs[obj[\"query_id\"]] += ',' + obj['cand_id']\n",
    "    #print(len(specter_dataset))\n",
    "    #print(len(proposed_dataset))\n",
    "    print(format(time.time() - t0, \".3f\"), \" seconds wall time to fetch specter & proposed.\")\n",
    "    return specter_dataset_local, proposed_dataset_local, corpusId_potential_reviewrs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def save_files(datasource, finename, namextension):\n",
    "    with open(PATH + finename + namextension + '.json', 'w', encoding='utf-8') as writefile:\n",
    "        json.dump(datasource, writefile, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def gen_reviewers_hash(reviewer_metafile):\n",
    "    t0 = time.time() # measure wall time\n",
    "    r_meta_data = []\n",
    "    reviewers_hash = {}\n",
    "    index = 0\n",
    "    reviewer_readfile = PATH + reviewer_metafile + '.jsonl'\n",
    "    with jsonlines.open(reviewer_readfile) as readR:\n",
    "        for obj in readR:\n",
    "            items = get_paper_by_ids(obj['papers'])\n",
    "            temp_data = {\"r_id\": obj[\"r_id\"], 'papers': items}\n",
    "            r_meta_data.append(temp_data)\n",
    "            print(index, end='\\r')\n",
    "            index += 1\n",
    "    save_files(r_meta_data, reviewer_metafile, '_papers_meta')\n",
    "    for r_meta in r_meta_data:\n",
    "        reviewers_hash[r_meta['r_id']] = r_meta['papers']\n",
    "    print(format(time.time() - t0, \".3f\"), \" seconds wall time to gen reviewers_hash.\")\n",
    "    return reviewers_hash"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def gen_peer_review_cosine(corpusId_potential_reviewrs,\n",
    "                                        reviewers_hash,\n",
    "                                        specter_dataset,\n",
    "                                        proposed_dataset):\n",
    "    t0 = time.time() # measure wall time\n",
    "    cosine_results_local = []\n",
    "    index = 0\n",
    "    print(len(corpusId_potential_reviewrs))\n",
    "    for corpusId, potential_reviewrs in corpusId_potential_reviewrs.items():\n",
    "        parts = potential_reviewrs.split(',')\n",
    "        if index == 16:\n",
    "            print(f'{index}: {len(parts)}')\n",
    "        for reviewerID in parts:\n",
    "            #print(reviewerID)\n",
    "            specter_cosines = []\n",
    "            proposed_cosines = []\n",
    "            counter = 0\n",
    "            if reviewerID in reviewers_hash.keys():\n",
    "                for k in range(len(reviewers_hash[reviewerID])):\n",
    "                    #print(reviewers_hash[reviewerID][k]['corpusId'])\n",
    "                    if reviewers_hash[reviewerID][k] is not None and int(reviewers_hash[reviewerID][k]['corpusId']) in map0:\n",
    "                        #print(reviewers_hash[reviewerID][k]['corpusId'])\n",
    "                        specter_dataset[reviewers_hash[reviewerID][k]['corpusId']] = emb0[map0[int(reviewers_hash[reviewerID][k]['corpusId'])].tolist()]\n",
    "                        proposed_dataset[reviewers_hash[reviewerID][k]['corpusId']] = emb1[map1[int(reviewers_hash[reviewerID][k]['corpusId'])].tolist()]\n",
    "                        # Calculating cosign similarity\n",
    "                        specter_cosines.append(dot(specter_dataset[corpusId], specter_dataset[reviewers_hash[reviewerID][k]['corpusId']])/(norm(specter_dataset[corpusId])*norm(specter_dataset[reviewers_hash[reviewerID][k]['corpusId']])))\n",
    "                        proposed_cosines.append(dot(proposed_dataset[corpusId], proposed_dataset[reviewers_hash[reviewerID][k]['corpusId']])/(norm(proposed_dataset[corpusId])*norm(proposed_dataset[reviewers_hash[reviewerID][k]['corpusId']])))\n",
    "                        counter += 1\n",
    "\n",
    "                if len(specter_cosines) < 3:\n",
    "                    num_of_papers = len(specter_cosines)\n",
    "                else:\n",
    "                    num_of_papers = 3\n",
    "\n",
    "                if len(specter_cosines) == 0:\n",
    "                    mean_specter_cosines = 0\n",
    "                    mean_proposed_cosines = 0\n",
    "\n",
    "                else:\n",
    "                    mean_specter_cosines = statistics.mean(sorted(specter_cosines[:num_of_papers]))\n",
    "                    mean_proposed_cosines = statistics.mean(sorted(proposed_cosines[:num_of_papers]))\n",
    "                cosine_results_local.append({'corpusId': corpusId, 'r_id': reviewerID,\n",
    "                                  'specter_score': str(mean_specter_cosines), 'proposed_score': str(mean_proposed_cosines),\n",
    "                                  'numOfPapers': counter, 'numOfPapersWEmbed': num_of_papers})\n",
    "        print(index, end='\\r')\n",
    "        index += 1\n",
    "    print(format(time.time() - t0, \".3f\"), \" seconds wall time to gen gen_peer_review_cosine.\")\n",
    "    return cosine_results_local"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.172  seconds wall time to fetch specter & proposed.\n",
      "448.542  seconds wall time to gen reviewers_hash.\n",
      "34\n",
      "16\r"
     ]
    }
   ],
   "source": [
    "specter_dataset, proposed_dataset, corpusId_potential_reviewrs = gen_corpusId_potential_reviewrs(softFile, hardFile)\n",
    "reviewers_hash = gen_reviewers_hash(reviewer_metafile)\n",
    "cosine_results = gen_peer_review_cosine(corpusId_potential_reviewrs,\n",
    "                                        reviewers_hash,\n",
    "                                        specter_dataset,\n",
    "                                        proposed_dataset)\n",
    "save_files(cosine_results, reviewer_metafile, '_papers_meta_scores')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}