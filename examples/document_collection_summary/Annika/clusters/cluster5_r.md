## Cluster 5 Papers

Number papers: 30
<html><table><tr>
<th>Paper Link</th>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/0abcbdf40f872e6baf1c082811d4ae93df787698>Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/1670a07b70f90cc4ddba71343e6a7ee4b5198595>Evaluating Gender Bias in Machine Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/5334e1857e910e2c7855c909c9495fb0ea28efbb>Does Gender Matter? Towards Fairness in Dialogue Systems</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/004fbcb0f3248afcbc158d97d3b02f0ea42e137a>On Measuring Gender Bias in Translation of Gender-neutral Pronouns</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/50154080ccbaec1a3b4ba401bebd94b80225d21a>Equalizing Gender Bias in Neural Machine Translation with Word Embeddings Techniques</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/22d3dfd27bfd4ec00ab6d9744cec851982e9b89a>Queens Are Powerful Too: Mitigating Gender Bias in Dialogue Generation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/5019dbe8d1da5f128f4f373d6849095cf18fd519>The Woman Worked as a Babysitter: On Biases in Language Generation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/a5ccd107c08c5a73ee89aee00a15bc4a0c8f7397>“You Sound Just Like Your Father” Commercial Machine Translation Systems Include Stylistic Biases</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/3cf1da52ee85335972533e56f9a5c1383ebbf2a3>Type B Reflexivization as an Unambiguous Testbed for Multilingual Multi-Task Gender Bias</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/6cf0dcb9a1746faeea378c18e22fdff0f8f772df>Reducing Unintended Identity Bias in Russian Hate Speech Detection</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/59bb7f41e72bae283f8aa2222b346956ee197a7a>Measuring Social Biases in Grounded Vision and Language Embeddings</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/e02c114d6269f4781b0fa92f4e2c9376e7462906>PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/0ec122ced09eda481239db7c6db6bb66ff635229>Mitigating Gender Bias for Neural Dialogue Generation with Adversarial Learning</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/ddfcda2b255633b5d5ad8ad37a4f4cb45e60af5a>Towards Controllable Biases in Language Generation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/352c0a78f008fcac02a46cf27cbe8261631f084e>Detect and Perturb: Neutral Rewriting of Biased and Sensitive Text via Gradient-based Decoding</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/a1715f0183fab5d4376143169251c1a5919e567a>Examining Covert Gender Bias: A Case Study in Turkish and English Machine Translation Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/1d7a01914b6ba54c3ca76ecee51edc1ec1cd6984>Style Pooling: Automatic Text Style Obfuscation for Improved Classification Fairness</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/6f9fc51102cf49bff4f4e2b336739a45f8389c80>Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/76a786b1acd6d1aca56e12a8a1db34569fdf9f3a>Societal Biases in Language Generation: Progress and Challenges</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/d48d1e80b6ea9708fa3a09d1556a7ced3b147da2>Collecting a Large-Scale Gender Bias Dataset for Coreference Resolution and Machine Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/6a89148ec6f14d7e89d791febabc88537876ce5b>How do people interact with biased text prediction models while writing?</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/8c90bfe05c06fd47eaec0f5b1662e06862572afe>Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/4919cd4ad287a3f0679846bd95c6805cb8dda4bd>Generating Biographies on Wikipedia: The Impact of Gender Bias on the Retrieval-Based Generation of Women Biographies</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/e0fc811aa01ae11169aae97b58c8334f8ca173d8>Measuring and Mitigating Name Biases in Neural Machine Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/3c759e2f16bfde8d31189631e4893d3ac8ff05f2>Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/1e83a4a3cc65229403a5f90229007af957c12602>Worst of Both Worlds: Biases Compound in Pre-trained Vision-and-Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/05fe77337bb43d4efd2c042c9bd5f044bb6e2271>NeuS: Neutral Multi-News Summarization for Mitigating Framing Bias</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/6d23532a1e9a8116041fd5aac6b0ef8ddd6d8171>The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/294292881447169461a6fcefbe8951b5b05528a8>Challenges in Measuring Bias via Open-Ended Language Generation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/3a6a97a50695d43d95a015bbb554b2bc0d40394e>Don’t Blame the Annotator: Bias Already Starts in the Annotation Instructions</a></td>
</tr>
</table></html>
