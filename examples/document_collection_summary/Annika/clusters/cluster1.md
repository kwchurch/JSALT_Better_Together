## Cluster 1 Papers

Number papers: 45
<html><table><tr>
<th>Paper Link</th>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/0abcbdf40f872e6baf1c082811d4ae93df787698>Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/1670a07b70f90cc4ddba71343e6a7ee4b5198595>Evaluating Gender Bias in Machine Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/f080e7f62cc50b8f1e922102414ca21a01647076>A Comparative Study of English-Chinese Translations of Court Texts by Machine and Human Translators and the Word2Vec Based Similarity Measure’s Ability To Gauge Human Evaluation Biases</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/004fbcb0f3248afcbc158d97d3b02f0ea42e137a>On Measuring Gender Bias in Translation of Gender-neutral Pronouns</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/22d3dfd27bfd4ec00ab6d9744cec851982e9b89a>Queens Are Powerful Too: Mitigating Gender Bias in Dialogue Generation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/5019dbe8d1da5f128f4f373d6849095cf18fd519>The Woman Worked as a Babysitter: On Biases in Language Generation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/a5ccd107c08c5a73ee89aee00a15bc4a0c8f7397>“You Sound Just Like Your Father” Commercial Machine Translation Systems Include Stylistic Biases</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/babeda48b10a4d638252118f2238d05a06f4ec55>StereoSet: Measuring stereotypical bias in pretrained language models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/216ef2817be8b4ba63c1ce9df315bea6f238d6c8>“This is a Problem, Don’t You Agree?” Framing and Bias in Human Evaluation for Natural Language Generation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/3cf1da52ee85335972533e56f9a5c1383ebbf2a3>Type B Reflexivization as an Unambiguous Testbed for Multilingual Multi-Task Gender Bias</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/645bd6eadc247989abc5e0b0aa0be79ec8b11ea6>CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/59bb7f41e72bae283f8aa2222b346956ee197a7a>Measuring Social Biases in Grounded Vision and Language Embeddings</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/7096304d19457833972daec4d3f5107befe30b1c>Do Neural Language Models Overcome Reporting Bias?</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/8b9fcd46ffe309a2eaa8eb675940191f5d41744c>Mitigating Gender Bias in Machine Translation with Target Gender Annotations</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/f72983cef733670d6915e37383257f548b5a3365>UNQOVERing Stereotypical Biases via Underspecified Questions</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/e02c114d6269f4781b0fa92f4e2c9376e7462906>PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/00059087c954c1af6ece33115315e3e0ecc2f2c2>Reducing Gender Bias in Neural Machine Translation as a Domain Adaptation Problem</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/ddfcda2b255633b5d5ad8ad37a4f4cb45e60af5a>Towards Controllable Biases in Language Generation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/352c0a78f008fcac02a46cf27cbe8261631f084e>Detect and Perturb: Neutral Rewriting of Biased and Sensitive Text via Gradient-based Decoding</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/996f0d401acd11e95ce5586010e7e4e18f5c3bb9>How to Split: the Effect of Word Segmentation on Gender Bias in Speech Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/7d5c661fa9a4255ee087e861f820564ea2e2bd6b>BBQ: A hand-built bias benchmark for question answering</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/0f192e9c7a1e3fdc6e051fc502f74b04c53bb3a3>On the Language Coverage Bias for Neural Machine Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/3e65f572322e192fe36ae52a8a7f025b0685dfc6>Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/6f9fc51102cf49bff4f4e2b336739a45f8389c80>Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/76a786b1acd6d1aca56e12a8a1db34569fdf9f3a>Societal Biases in Language Generation: Progress and Challenges</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/d48d1e80b6ea9708fa3a09d1556a7ced3b147da2>Collecting a Large-Scale Gender Bias Dataset for Coreference Resolution and Machine Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/63052e581f1b272eefdbf109a230c7ec87e1f79a>Gender bias amplification during Speed-Quality optimization in Neural Machine Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/130ab5c480860e330b65280a3410f17bb2d50fe1>Sustainable Modular Debiasing of Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/8fa0de4920c8edcb1fea698ff3463a347771d889>Stereotype and Skew: Quantifying Gender Bias in Pre-trained and Fine-tuned Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/6a89148ec6f14d7e89d791febabc88537876ce5b>How do people interact with biased text prediction models while writing?</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/ce9ca56036307217ea565644d3d3bd74b879e045>Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/20328647c38282088dc9dddedcb2e5bdaeeeea78>Text Style Transfer for Bias Mitigation using Masked Language Modeling</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/4919cd4ad287a3f0679846bd95c6805cb8dda4bd>Generating Biographies on Wikipedia: The Impact of Gender Bias on the Retrieval-Based Generation of Women Biographies</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/e0fc811aa01ae11169aae97b58c8334f8ca173d8>Measuring and Mitigating Name Biases in Neural Machine Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/8d9f0e34cfc659510d6c4ed085c6ef61734732b0>Under the Morphosyntactic Lens: A Multifaceted Evaluation of Gender Bias in Speech Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/3c759e2f16bfde8d31189631e4893d3ac8ff05f2>Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/5a5b5bd6c644eb43943144410efba704ebb4c083>Entropy-based Attention Regularization Frees Unintended Bias Mitigation from Lists</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/1e83a4a3cc65229403a5f90229007af957c12602>Worst of Both Worlds: Biases Compound in Pre-trained Vision-and-Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/fd69d6e5b7dbb9ae912f0ab98011d2891996252d>Ethical Considerations for Low-resourced Machine Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/d9424371662717c8981eef3d501d7ce59c66ce77>On the Intrinsic and Extrinsic Fairness Evaluation Metrics for Contextualized Language Representations</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/e6296cf7c2c7b4578f1ae644edae4ceee5a5faea>On Measuring Social Biases in Prompt-Based Multi-Task Learning</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/294292881447169461a6fcefbe8951b5b05528a8>Challenges in Measuring Bias via Open-Ended Language Generation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/de6807676d8171472ed6cf421c4e4ed3cbb47699>An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/1fbb406a7387451bb1b6b67a44975c65120ad03a>Debiasing Pretrained Text Encoders by Paying Attention to Paying Attention</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/3a6a97a50695d43d95a015bbb554b2bc0d40394e>Don’t Blame the Annotator: Bias Already Starts in the Annotation Instructions</a></td>
</tr>
</table></html>
