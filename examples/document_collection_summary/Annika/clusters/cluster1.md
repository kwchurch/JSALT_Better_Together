## Cluster 1 Papers

<html><table><tr>
<th>Paper Link</th>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/d6ddc4f4c81c9565019be1983d37f9fbdf5bd057>The Birth of Bias: A case study on the evolution of gender bias in an English language model</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/c9cf6cbfda627680361a42339521eebd460ee6b2>A Comparative Study on Word Embeddings and Social NLP Tasks</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/21b2441907aa23b0251c0bb7af68b08c4b94f4df>Using Item Response Theory to Measure Gender and Racial Bias of a BERT-based Automated English Speech Assessment System</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/ab722f0efc91446d5e2ee519ea621ba1c15babc1>An Empirical Study on the Fairness of Pre-trained Word Embeddings</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/ecee71b8599818dedb46ce3e1245f1c94b6cbb82>Unsupervised Mitigating Gender Bias by Character Components: A Case Study of Chinese Word Embedding</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/853a43c4fc36038d70763b592704cdb813169a00>Gender Biases and Where to Find Them: Exploring Gender Bias in Pre-Trained Transformer-based Language Models Using Movement Pruning</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/18dd0387aef81ec00b327fdc81ea9b4d07b2eddb>Why Knowledge Distillation Amplifies Gender Bias and How to Mitigate from the Perspective of DistilBERT</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/7e7cc29b042793b27688beb765dc604dee65d536>Flexible text generation for counterfactual fairness probing</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/bbf0af4a727fc186ef173aba3518fc0db11bb9d4>Don’t Forget About Pronouns: Removing Gender Bias in Language Models Without Losing Factual Gender Information</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/3a37fef290d76029c295201cc168c0f8ecb0a0cf>Fewer Errors, but More Stereotypes? The Effect of Model Size on Gender Bias</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/e404b81b13d6cd07259d8560a5e77359f930ec2e>Indigenous Language Revitalization and the Dilemma of Gender Bias</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/5a0b974dc9eaa6633808a0f6699592ee5254ac20>Analysis of Gender Bias in Social Perception and Judgement Using Chinese Word Embeddings</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/4afb1dd5ec9093c2d61b86e8faf74fd5a6807cd0>On Gender Biases in Offensive Language Classification Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/704dafb9ae3f9b452c96a86d30207f1193459c31>Gender Bias in BERT - Measuring and Analysing Biases through Sentiment Rating in a Realistic Downstream Classification Task</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/42827df167cc7d87774626a7c913d1cdaaa47d10>Occupational Biases in Norwegian and Multilingual Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/e8a8529dd1e0b0662505db1743c48d8ebd748340>Evaluating Gender Bias Transfer from Film Data</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/930b7fb33fe18832574952a77ef61634f40e44e8>A Taxonomy of Bias-Causing Ambiguities in Machine Translation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/ea0e62db166caa46de8821acce1afe1b8793025b>Using Natural Sentence Prompts for Understanding Biases in Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/48be558f86101bbd60a41621daceb8a27141852e>Features or Spurious Artifacts? Data-centric Baselines for Fair and Robust Hate Speech Detection</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/e2de6848ea05ecec6749b574ea798cbbc9c0f871>Assessing Group-level Gender Bias in Professional Evaluations: The Case of Medical Student End-of-Shift Feedback</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/b4cd18f01b37c98e5e7652c23dece7e977215ef8>Uncertainty and Inclusivity in Gender Bias Annotation: An Annotation Taxonomy and Annotated Datasets of British English Text</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/f19298ea19dcd7bd69ab76cf6a18f801052e26e4>On the Machine Learning of Ethical Judgments from Natural Language</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/d6f002d88638de71114dab083f0ea8ceea6b6a5a>Benchmarking Intersectional Biases in NLP</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/a452c3fe8d7d5199afe66e1db519f528df3f487f>Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/b0096a2431773e34e5c72f559b87e01f5c15d5e0>Choose Your Lenses: Flaws in Gender Bias Evaluation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/7c64650af4e4db5291f733f41ee470f2ce22f9db>An Empirical Study on Pseudo-log-likelihood Bias Measures for Masked Language Models Using Paraphrased Sentences</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/ddc7e9cadb1da5b0102b843e430005b7c2173689>DeBiasByUs: Raising Awareness and Creating a Database of MT Bias</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/058dee85d522f6565fe1502cafcf9a5e3f6a6f0e>Measuring Fairness with Biased Rulers: A Comparative Study on Bias Metrics for Pre-trained Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/0ace520bf2d50d6233fceb0845037cb2a88074c9>The ethical role of computational linguistics in digital psychological formulation and suicide prevention.</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/84b6660b717fd4832fedbe066f622ef183662a69>Theory-Grounded Measurement of U.S. Social Stereotypes in English Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/23c818b5df6a2c8f8837f0e69741164f01946fef>How well can Text-to-Image Generative Models understand Ethical Natural Language Interventions?</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/969f45a3adf5e0bcf741447b1c67a0f3a386801a>BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/8f16c64af8021a881cc092a215bf57391d2668d0>Ethics consideration sections in natural language processing papers</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/a8c09c41f39d798dc4201eeec1452fe617e428df>Bridging Fairness and Environmental Sustainability in Natural Language Processing</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/7ef43bacd43393ff116e6fcda6a52a6902e016d7>“I’m sorry to hear that”: Finding New Biases in Language Models with a Holistic Descriptor Dataset</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/20e1ef6a126bd9bc0b4e899debbf65c6baa21652>MABEL: Attenuating Gender Bias using Textual Entailment Data</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/641f1e845c5baa1b6282a803a928c83290ddf669>Measuring Gender Bias in West Slavic Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/1669a5929c6706efaec0fe2ddb4a62130bd93cb3>Toward Cultural Bias Evaluation Datasets: The Case of Bengali Gender, Religious, and National Identity</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/c52cc36737f382a3652da5602bba0678aea0078e>Bias assessment for experts in discrimination, not in computer science</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/75ddc4fb91332f95222d74449d96b9f7c8f976c7>Nationality Bias in Text Generation</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/7711d788b73f04635a5cc0ab4bd7bcbe9665bce7>Fair Enough: Standardizing Evaluation and Model Selection for Fairness Research in NLP</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/b3dcd48b68bdbb304fa53299496539c054638e0c>Logic Against Bias: Textual Entailment Mitigates Stereotypical Sentence Reasoning</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/4dcef4d040cdbc17eb8e7e39d1456c2a1ab691a0>SODAPOP: Open-Ended Discovery of Social Biases in Social Commonsense Reasoning Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/a5bc3c0bce8d105a6b95f999fed4ea59c342cb1d>Multi-Modal Bias: Introducing a Framework for Stereotypical Bias Assessment beyond Gender and Race in Vision–Language Models</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/a722010cc6bb9fffe3b9a06bf9586b5d40bc50f7>Measuring Normative and Descriptive Biases in Language Models Using Census Data</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/fe7a0612b24b48fe09304af39cdb27d8e33697c6>Parameter-efficient Modularised Bias Mitigation via AdapterFusion</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/c21cd6401032f30c4165754d29bd0a7e90582bfd>Comparing Intrinsic Gender Bias Evaluation Measures without using Human Annotated Examples</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/f48287e9ed131ff8ffa79b66717887c5af74f203>When Do Pre-Training Biases Propagate to Downstream Tasks? A Case Study in Text Summarization</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/82040a4a1b1bceb5216a9dd09e5d9c8fa3fdd83f>How Far Can It Go? On Intrinsic Gender Bias Mitigation for Text Classification</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/78665358e27c6c09fbb99b7642b70834666993b9>In-Depth Look at Word Filling Societal Bias Measures</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/128904f804d206d2b2a512358df4d4385b7d2712>Social Commonsense for Explanation and Cultural Bias Discovery</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/fd26c019d889b816c28fa2e15e2571faa78592bb>Counter-GAP: Counterfactual Bias Evaluation through Gendered Ambiguous Pronouns</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/12902f724619344dfeae330043c4b7b1c9d99bd0>Understanding Ethics in NLP Authoring and Reviewing</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/181ad8a919e6fa7adc2226ff1b852e22e19440dd>A Multilingual Dataset of Racial Stereotypes in Social Media Conversational Threads</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/e9a0354615a649b0fc87b046ec8ccd29d4380606>Investigating anatomical bias in clinical machine learning algorithms</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/cd37a330aca9fbdb54716e4e43710ba4b125fc2c>Model-Agnostic Bias Measurement in Link Prediction</a></td>
</tr>
<tr>
<td><a href=https://www.semanticscholar.org/paper/116e06573858b9d767355f51f302e2c75b410ca2>Fairness in Language Models Beyond English: Gaps and Challenges</a></td>
</tr>
</table></html>
